{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS1TV7cOYnWM"
   },
   "source": [
    "# Emotion Classification in short texts with BERT\n",
    "\n",
    "Applying BERT to the problem of multiclass text classification. Our dataset consists of written dialogs, messages and short stories. Each dialog utterance/message is labeled with one of the five emotion categories: joy, anger, sadness, fear, neutral. \n",
    "\n",
    "## Workflow: \n",
    "1. Import Data\n",
    "2. Data preprocessing and downloading BERT\n",
    "3. Training and validation\n",
    "4. Saving the model\n",
    "\n",
    "Multiclass text classification with BERT and [ktrain](https://github.com/amaiya/ktrain). Use google colab for a free GPU \n",
    "\n",
    "ðŸ‘‹  **Let's start** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "3ckm3TIdYnxF",
    "outputId": "e466435e-bfae-4312-e17b-63f4c76e15c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "  Downloading ktrain-0.21.3.tar.gz (25.3 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (0.22.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1059: The handshake operation timed out'))': /simple/ktrain/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (3.1.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (1.0.5)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting keras_bert>=0.81.0\n",
      "  Downloading keras-bert-0.86.0.tar.gz (26 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (2.24.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (0.16.0)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\59\\f6\\9d\\85068904dba861c0b9af74e286265a08da438748ee5ae56067\\langdetect-1.0.8-py3-none-any.whl\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\24\\aa\\17\\5bc7c72e9a37990a9620cc3aad0acad1564dcff6dbc2359de3\\jieba-0.42.1-py3-none-any.whl\n",
      "Collecting cchardet\n",
      "  Downloading cchardet-2.1.6-cp37-cp37m-win_amd64.whl (115 kB)\n",
      "Requirement already satisfied: networkx>=2.3 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (2.4)\n",
      "Requirement already satisfied: bokeh in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (2.1.1)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\dc\\cc\\62\\a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\\seqeval-0.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: packaging in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (20.4)\n",
      "Collecting transformers>=3.1.0\n",
      "  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: ipython in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ktrain) (7.16.1)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\5e\\c2\\33\\e5d7d8f2f8b0c391d76bf82b844c3151bf23a84d75d02b185f\\syntok-1.3.1-py3-none-any.whl\n",
      "Collecting whoosh\n",
      "  Using cached Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->ktrain) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->ktrain) (1.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2020.1)\n",
      "Requirement already satisfied: Keras>=2.4.3 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from keras_bert>=0.81.0->ktrain) (2.4.3)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\b3\\67\\58\\bcfb43b6ab764496a446021a8d05991adffd48c16582381326\\keras_transformer-0.38.0-py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from requests->ktrain) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from requests->ktrain) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from requests->ktrain) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: six in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from langdetect->ktrain) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
      "Requirement already satisfied: pillow>=4.0 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from bokeh->ktrain) (7.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from bokeh->ktrain) (2.11.2)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from bokeh->ktrain) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from bokeh->ktrain) (3.7.4.2)\n",
      "Requirement already satisfied: tornado>=5.1 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from bokeh->ktrain) (6.0.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from transformers>=3.1.0->ktrain) (4.47.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from transformers>=3.1.0->ktrain) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from transformers>=3.1.0->ktrain) (2020.6.8)\n",
      "Collecting tokenizers==0.8.1.rc2\n",
      "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\69\\09\\d1\\bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\\sacremoses-0.0.43-py3-none-any.whl\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.91-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (0.4.3)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (0.15.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (4.3.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (2.6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (49.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from ipython->ktrain) (0.7.5)\n",
      "Requirement already satisfied: h5py in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from Keras>=2.4.3->keras_bert>=0.81.0->ktrain) (2.10.0)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\65\\66\\e9\\c7eafddc29b81a98786f12b48a2aee7e3c633f6bf4a62cbc20\\keras_pos_embd-0.11.0-py3-none-any.whl\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\21\\38\\cc\\50e6d62d6d458e8223d3ddaef7c622b67ae57708193918051b\\keras_multi_head-0.27.0-py3-none-any.whl\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\9e\\53\\a2\\651c985b605e6a6c48688c779808eb1956fabb910b0557d871\\keras_position_wise_feed_forward-0.6.0-py3-none-any.whl\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\58\\14\\24\\76b0d99b7d9cc17e110956e0fae825a5da3e70a60273220502\\keras_layer_normalization-0.14.0-py3-none-any.whl\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\2d\\31\\2c\\2d3fb4442f6112b92cd56bf801ff25421f302c755f935d4a79\\keras_embed_sim-0.8.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=3.1.0->ktrain) (7.1.2)\n",
      "Requirement already satisfied: parso>=0.5.2 in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->ktrain) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\chenx\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
      "Processing c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\ec\\f7\\48\\30de93f8333298bad9202aab9b04db0cfd58dcd379b5a5ef1c\\keras_self_attention-0.46.0-py3-none-any.whl\n",
      "Building wheels for collected packages: ktrain, keras-bert\n",
      "  Building wheel for ktrain (setup.py): started\n",
      "  Building wheel for ktrain (setup.py): finished with status 'done'\n",
      "  Created wheel for ktrain: filename=ktrain-0.21.3-py3-none-any.whl size=25270205 sha256=4d79d571a7b615e6d3670942289dfb7b106947fbfa9530ee0e36fdaa0f445463\n",
      "  Stored in directory: c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\0c\\98\\fc\\0738e516f4bdfea4812b28cd7a512104d8c1748a9da4373405\n",
      "  Building wheel for keras-bert (setup.py): started\n",
      "  Building wheel for keras-bert (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.86.0-py3-none-any.whl size=34149 sha256=9a7623c0752d38407d81d07cd3b918e69ae2638ab2baf4639afc1d556b6e4d31\n",
      "  Stored in directory: c:\\users\\chenx\\appdata\\local\\pip\\cache\\wheels\\fc\\c1\\0a\\eb9187261b3f192ac314aefb54fe66f50540c3edb906599633\n",
      "Successfully built ktrain keras-bert\n",
      "Installing collected packages: fastprogress, keras-pos-embd, keras-self-attention, keras-multi-head, keras-position-wise-feed-forward, keras-layer-normalization, keras-embed-sim, keras-transformer, keras-bert, langdetect, jieba, cchardet, seqeval, tokenizers, sacremoses, sentencepiece, transformers, syntok, whoosh, ktrain\n",
      "Successfully installed cchardet-2.1.6 fastprogress-1.0.0 jieba-0.42.1 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.21.3 langdetect-1.0.8 sacremoses-0.0.43 sentencepiece-0.1.91 seqeval-0.0.12 syntok-1.3.1 tokenizers-0.8.1rc2 transformers-3.2.0 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "# install ktrain on Google Colab\n",
    "!pip3 install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "FYJa3hJiYnWP",
    "outputId": "0f7f0dec-cdf8-48a5-fe4c-fb7695f76856"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\chenx\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33Sa8kVvYnWR"
   },
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "colab_type": "code",
    "id": "xGRw5awSX7mZ",
    "outputId": "b0b110b6-a3ed-48a3-e46f-5071475dffde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set: 7934\n",
      "size of validation set: 3393\n",
      "joy        2326\n",
      "sadness    2317\n",
      "anger      2259\n",
      "neutral    2254\n",
      "fear       2171\n",
      "Name: Emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>There are tons of other paintings that I thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Yet the dog had grown old and less capable , a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I get into the tube or the train without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>This last may be a source of considerable disq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>She disliked the intimacy he showed towards so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When my family heard that my Mother's cousin w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>joy</td>\n",
       "      <td>Finding out I am chosen to collect norms for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anger</td>\n",
       "      <td>A spokesperson said : ` Glen is furious that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Yes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I see people with burns I feel sad, actua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral   There are tons of other paintings that I thin...\n",
       "1  sadness  Yet the dog had grown old and less capable , a...\n",
       "2     fear  When I get into the tube or the train without ...\n",
       "3     fear  This last may be a source of considerable disq...\n",
       "4    anger  She disliked the intimacy he showed towards so...\n",
       "5  sadness  When my family heard that my Mother's cousin w...\n",
       "6      joy  Finding out I am chosen to collect norms for C...\n",
       "7    anger  A spokesperson said : ` Glen is furious that t...\n",
       "8  neutral                                             Yes . \n",
       "9  sadness  When I see people with burns I feel sad, actua..."
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv', encoding='utf-8')\n",
    "data_test = pd.read_csv('data/data_test.csv', encoding='utf-8')\n",
    "\n",
    "X_train = data_train.Text.tolist()\n",
    "X_test = data_test.Text.tolist()\n",
    "\n",
    "y_train = data_train.Emotion.tolist()\n",
    "y_test = data_test.Emotion.tolist()\n",
    "\n",
    "data = data_train.append(data_test, ignore_index=True)\n",
    "\n",
    "class_names = ['joy', 'sadness', 'fear', 'anger', 'neutral']\n",
    "\n",
    "print('size of training set: %s' % (len(data_train['Text'])))\n",
    "print('size of validation set: %s' % (len(data_test['Text'])))\n",
    "print(data.Emotion.value_counts())\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBxd1kYYYnWU"
   },
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    'joy': 0,\n",
    "    'sadness': 1,\n",
    "    'fear': 2,\n",
    "    'anger': 3,\n",
    "    'neutral': 4\n",
    "}\n",
    "\n",
    "# Integer values for each class\n",
    "y_train = [encoding[x] for x in y_train]\n",
    "y_test = [encoding[x] for x in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pcuN5eklYnWW"
   },
   "source": [
    "## 2. Data preprocessing\n",
    "\n",
    "* The text must be preprocessed in a specific way for use with BERT. This is accomplished by setting preprocess_mode to â€˜bertâ€™. The BERT model and vocabulary will be automatically downloaded\n",
    "\n",
    "* BERT can handle a maximum length of 512, but let's use less to reduce memory and improve speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "IQnZnKQmZA3U",
    "outputId": "38dcedee-706f-4d32-e578-976b8b55826c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=X_train, y_train=y_train,\n",
    "                                                                       x_test=X_test, y_test=y_test,\n",
    "                                                                       class_names=class_names,\n",
    "                                                                       preprocess_mode='bert',\n",
    "                                                                       maxlen=350, \n",
    "                                                                       max_features=35000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4fuvHPnYnWY"
   },
   "source": [
    "## 2. Training and validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KwBXM9BYnWZ"
   },
   "source": [
    "Loading the pretrained BERT for text classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "1cGb2CaOZBNS",
    "outputId": "4d05d637-9692-45e3-8ada-0dab9603480e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 350\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkgvS2pvYnWb"
   },
   "source": [
    "Wrap it in a Learner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zu8uv-xKYnWc"
   },
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=(x_train, y_train), \n",
    "                             val_data=(x_test, y_test),\n",
    "                             batch_size=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4YY0JBAYnWd"
   },
   "source": [
    "Train the model. More about tuning learning rates [here](https://github.com/amaiya/ktrain/blob/master/tutorial-02-tuning-learning-rates.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "jD-2RpgkZN_n",
    "outputId": "74ab6af9-e127-44b2-bb14-eb23b3ed17d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Train on 7934 samples, validate on 3393 samples\n",
      "Epoch 1/3\n",
      "7934/7934 [==============================] - 475s 60ms/sample - loss: 0.9311 - acc: 0.6364 - val_loss: 0.5669 - val_acc: 0.8034\n",
      "Epoch 2/3\n",
      "7934/7934 [==============================] - 466s 59ms/sample - loss: 0.4569 - acc: 0.8470 - val_loss: 0.5211 - val_acc: 0.8232\n",
      "Epoch 3/3\n",
      "7934/7934 [==============================] - 466s 59ms/sample - loss: 0.1911 - acc: 0.9411 - val_loss: 0.5589 - val_acc: 0.8320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa776ace10>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(2e-5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xHhddIieYnWg"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "2s4ao_e2i4ld",
    "outputId": "fd6d79ca-5d3d-41b0-86ff-a8d331e2847d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy       0.87      0.85      0.86       707\n",
      "     sadness       0.84      0.79      0.82       676\n",
      "        fear       0.86      0.87      0.86       679\n",
      "       anger       0.81      0.80      0.81       693\n",
      "     neutral       0.78      0.85      0.81       638\n",
      "\n",
      "    accuracy                           0.83      3393\n",
      "   macro avg       0.83      0.83      0.83      3393\n",
      "weighted avg       0.83      0.83      0.83      3393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[598,   8,  15,  13,  73],\n",
       "       [ 18, 537,  37,  54,  30],\n",
       "       [ 16,  20, 590,  40,  13],\n",
       "       [ 19,  49,  35, 557,  33],\n",
       "       [ 37,  24,  12,  24, 541]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(val_data=(x_test, y_test), class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MI0nWZlhYnWi"
   },
   "source": [
    "#### Testing with other inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6eDpFIoXjlE8",
    "outputId": "a59d84b8-ec69-4253-bfa3-7364bb791fb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'sadness', 'fear', 'anger', 'neutral']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)\n",
    "predictor.get_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w5KQfwX8xLLu",
    "outputId": "99d2ba47-87ba-4e96-c03f-558746e91ede"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: sadness (0.06)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "message = 'I just broke up with my boyfriend'\n",
    "\n",
    "start_time = time.time() \n",
    "prediction = predictor.predict(message)\n",
    "\n",
    "print('predicted: {} ({:.2f})'.format(prediction, (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rusM_SzpYnWm"
   },
   "source": [
    "## 4. Saving Bert model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBkGko4Sz2ef"
   },
   "outputs": [],
   "source": [
    "# let's save the predictor for later use\n",
    "predictor.save(\"models/bert_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQo2P03tYnWo"
   },
   "source": [
    "Done! to reload the predictor use: ktrain.load_predictor"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
